Title: 2024-05-18

----

Text: [{"content":{"text":"<p>Ciao! La newsletter di questa settimana è in buona parte dedicata alle novità nel campo dell'intelligenza artificiale di OpenAI e Google, ma parliamo anche di cloud europeo, 5G, data breach e altro.</p>"},"id":"e22566f2-f190-4017-8f58-e54d19e40d92","isHidden":false,"type":"text"},{"content":[],"id":"2dd6a1e4-b7bb-4eb2-9b26-cc6041474a36","isHidden":false,"type":"newsletter-subscribe"},{"content":{"text":"INTELLIGENZA ARTIFICIALE"},"id":"0e3bc4ad-4d83-46d3-9102-3ab50a6a36af","isHidden":false,"type":"newsletter-v2-section-header"},{"content":{"text":"OpenAI ci mostra il futuro degli assistenti virtuali con GPT-4o"},"id":"30dfbfcd-9f61-4189-95e1-96a1b05911d4","isHidden":false,"type":"newsletter-v2-section-title"},{"content":{"text":"<p>Lunedì scorso OpenAI ha presentato un nuovo modello di intelligenza artificiale chiamato GPT-4o. È il miglior modello mai realizzato da OpenAI e oltre ad essere più preciso, più veloce e meno costoso ha la grande novità di essere nativamente multimodale. Significa cioè che è in grado di comprendere non solo del testo ma anche le immagini e i suoni, e di generare risposte vocali. Il tutto senza passaggi intermedi come ad esempio la trascrizione dell'audio. OpenAI l'ha chiamato l'«omnimodello» (da cui la \"o\").</p>"},"id":"fb330fd9-353e-45b4-b2a7-b45bbdbc3015","isHidden":false,"type":"text"},{"content":{"location":"kirby","image":["file://fPYNvOwj8biYztUq"],"src":"","alt":"","caption":"","link":"https://www.youtube.com/watch?v=vgYi3Wr7v_g","ratio":"","crop":"false"},"id":"6d5cac90-bee8-4c75-9c1c-b5a3203af161","isHidden":false,"type":"image"},{"content":{"text":"<p>Il risultato mostrato da OpenAI nelle dimostrazioni è sorprendente. Si può conversare con l'assistente in modo molto naturale, anche interrompendolo, e il modello è in grado di comprendere le emozioni e il tono della voce, oltre a vedere quello che c'è intorno. Anche la voce di risposta è molto naturale, sa usare diverse intonazioni e stili e anche <a href=\"https://www.youtube.com/watch?v=MirzFk_DSiI\" target=\"_blank\">cantare</a>.</p><p>Un paio di applicazioni concrete che potrebbero avere un forte impatto sono la traduzione in tempo reale bidirezionale (<a href=\"https://www.youtube.com/watch?v=c2DFg53Zhvw\" target=\"_blank\">qua</a> un esempio tra inglese e italiano, con una pronuncia in realtà migliorabile) e l'accessibilità. In un video pubblicato da OpenAI GPT-4o è in grado di agire da assistente rispondendo alle domande di una persona ipovedente.</p>"},"id":"4829dabc-b62a-4801-b7e3-732818011df5","isHidden":false,"type":"text"},{"content":{"location":"kirby","image":["file://3fwDV9FJadDG0oRW"],"src":"","alt":"","caption":"","link":"https://www.youtube.com/watch?v=KwNUJ69RbwY","ratio":"","crop":"false"},"id":"0b23d8bb-5dd7-4827-8854-c727c28ca919","isHidden":false,"type":"image"},{"content":{"text":"<p>GPT-4o in versione \"testo\" sarà disponibile gratuitamente (con dei limiti) per tutti nelle prossime settimane, sia su chatgpt.com, nell'app ChatGPT e nella nuova app per macOS, mentre la modalità voce e video sarà resa disponibile solo agli abbonati a ChatGPT Plus.</p>"},"id":"47bbd9a5-6a48-4a9d-ad8f-d236f72cf7de","isHidden":false,"type":"text"},{"content":{"sources":[{"url":"https://openai.com/index/hello-gpt-4o/","name":"OpenAI"},{"url":"https://openai.com/index/gpt-4o-and-more-tools-to-chatgpt-free/","name":"OpenAI"},{"url":"https://www.hdblog.it/sicurezza/articoli/n582947/openai-annuncia-gpt-4o/","name":"HDblog"}]},"id":"1af51e7a-61af-47db-a967-208a44ef9840","isHidden":false,"type":"newsletter-sources"}]

----

Uuid: QgazDCXOedi6aLPQ